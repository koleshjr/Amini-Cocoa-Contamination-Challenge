{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVoKyI0pY6H5"
      },
      "source": [
        "# Amini Cocoa Contamination Challenge\n",
        "\n",
        "* We trained YOLOv5s models, which are fast to train (approx. 2h 30min per fold).\n",
        "* Based on the resource restrictions of this challenge, quoted below:\n",
        "\n",
        "  > \"Your solutions for this challenge must be able to function in a resource-limited setting, i.e., it should run on a low-resource smartphone. As such, we are imposing the following restrictions on resources: T4 GPU, maximum 9h training, maximum 3h inference. Model frameworks must be appropriate for use on edge devices (e.g., ONNX, TensorFlow Lite).\"\n",
        "\n",
        "* Since there were no restrictions placed on ensembling, and the YOLOv5s models are lightweight and fast to train, we trained an ensemble of three models on folds 6, 7, and 8.\n",
        "* The total inference time for the ensemble remained well under 1 hour â€” comfortably within the 3-hour inference budget.\n",
        "* All models can be exported to ONNX or TensorFlow Lite and are suitable for deployment on low-resource smartphones.\n",
        "* Based on the above, our solution adheres fully to the challenge rules.\n",
        "* That said, even the individual (single-fold) models perform strongly and are fast enough for edge deployment on their own.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJH7ooXeY1lw"
      },
      "outputs": [],
      "source": [
        "# Install ultralytics\n",
        "!pip -q install ultralytics==8.3.115\n",
        "!pip -q install ensemble_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:10.369534Z",
          "iopub.status.busy": "2025-04-22T12:20:10.369253Z",
          "iopub.status.idle": "2025-04-22T12:20:16.555929Z",
          "shell.execute_reply": "2025-04-22T12:20:16.555216Z",
          "shell.execute_reply.started": "2025-04-22T12:20:10.369506Z"
        },
        "id": "nejaj4WDYzwj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "from ultralytics import RTDETR, YOLO\n",
        "from ensemble_boxes import weighted_boxes_fusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:16.557313Z",
          "iopub.status.busy": "2025-04-22T12:20:16.556901Z",
          "iopub.status.idle": "2025-04-22T12:20:16.567120Z",
          "shell.execute_reply": "2025-04-22T12:20:16.566243Z",
          "shell.execute_reply.started": "2025-04-22T12:20:16.557285Z"
        },
        "id": "sOqe3G7vYzwk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(47)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:16.569880Z",
          "iopub.status.busy": "2025-04-22T12:20:16.569298Z",
          "iopub.status.idle": "2025-04-22T12:20:16.574864Z",
          "shell.execute_reply": "2025-04-22T12:20:16.574062Z",
          "shell.execute_reply.started": "2025-04-22T12:20:16.569839Z"
        },
        "id": "0POfOnjqYzwk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    path = \"/kaggle/input/amini-cocoa-contamination-dataset/\"\n",
        "    image_path = '/kaggle/input/amini-cocoa-contamination-dataset/dataset/images/test/'\n",
        "    folds = 5\n",
        "    nc=3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DgW3RDhYzwk"
      },
      "source": [
        "(1190916, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:16.576283Z",
          "iopub.status.busy": "2025-04-22T12:20:16.576018Z",
          "iopub.status.idle": "2025-04-22T12:20:16.600726Z",
          "shell.execute_reply": "2025-04-22T12:20:16.599848Z",
          "shell.execute_reply.started": "2025-04-22T12:20:16.576257Z"
        },
        "id": "xEp5S-ESYzwl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def run_yolo_inference_on_test_set(test_df, image_sizes, model_path, min_conf=0.001):\n",
        "    \"\"\"\n",
        "    Runs YOLO inference on all test images across multiple image sizes and stores predictions.\n",
        "\n",
        "    Args:\n",
        "        test_df (pd.DataFrame): Test dataset with image paths.\n",
        "        image_sizes (list): List of image sizes for multi-scale inference.\n",
        "        model_path (str): Path to YOLO model weights.\n",
        "        min_conf (float): Minimum confidence threshold.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of predictions for each image size.\n",
        "    \"\"\"\n",
        "    model = YOLO(model_path, task='detect')\n",
        "    model.eval()\n",
        "    model.training = False\n",
        "\n",
        "    all_predictions = defaultdict(list)\n",
        "\n",
        "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running YOLO Inference\"):\n",
        "        image = cv2.imread(row.image_path)\n",
        "        height, width, _ = image.shape\n",
        "\n",
        "        for size in image_sizes:\n",
        "            results = model(\n",
        "                image,\n",
        "                imgsz=size,\n",
        "                verbose=False,\n",
        "                conf=min_conf,\n",
        "                augment=True,\n",
        "                iou=0.4,\n",
        "                max_det=600\n",
        "            )[0]\n",
        "\n",
        "            boxes = results.boxes.xyxy.cpu().numpy()\n",
        "            classes = results.boxes.cls.cpu().numpy()\n",
        "            confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "            mask = confidences >= min_conf\n",
        "            boxes, classes, confidences = boxes[mask], classes[mask], confidences[mask]\n",
        "\n",
        "            if len(boxes) == 0:\n",
        "                print('No detection:', row.Image_ID)\n",
        "                all_predictions[size].append({\n",
        "                    'Image_ID': row.Image_ID,\n",
        "                    'class': 'None',\n",
        "                    'confidence': None,\n",
        "                    'ymin': None, 'xmin': None, 'ymax': None, 'xmax': None\n",
        "                })\n",
        "            else:\n",
        "                for box, cls, conf in zip(boxes, classes, confidences):\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    all_predictions[size].append({\n",
        "                        'Image_ID': row.Image_ID,\n",
        "                        'class': label_map[int(cls)],\n",
        "                        'confidence': conf,\n",
        "                        'ymin': y1, 'xmin': x1, 'ymax': y2, 'xmax': x2\n",
        "                    })\n",
        "    return all_predictions\n",
        "\n",
        "\n",
        "\n",
        "def merge_predictions_with_wbf(prediction_dfs, iou_thr=0.5, skip_box_thr=0.001):\n",
        "    \"\"\"\n",
        "    Applies Weighted Boxes Fusion on predictions from multiple models or image sizes.\n",
        "\n",
        "    Args:\n",
        "        prediction_dfs (list): List of prediction DataFrames.\n",
        "        iou_thr (float): IoU threshold for box fusion.\n",
        "        skip_box_thr (float): Confidence threshold to skip boxes.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Fused prediction results.\n",
        "    \"\"\"\n",
        "    DATA_DIR = '/kaggle/input/amini-cocoa-contamination-dataset/dataset/images/test'\n",
        "    fused_results = []\n",
        "    image_ids = pd.concat(prediction_dfs)['Image_ID'].unique()\n",
        "\n",
        "    for image_id in tqdm(image_ids, desc=\"Merging Predictions with WBF\"):\n",
        "        boxes_list, scores_list, labels_list = [], [], []\n",
        "        image_path = os.path.join(DATA_DIR, image_id)\n",
        "        image = cv2.imread(image_path)\n",
        "        h, w, _ = image.shape\n",
        "\n",
        "        for df in prediction_dfs:\n",
        "            df_image = df[df.Image_ID == image_id].copy()\n",
        "            boxes = df_image[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
        "            scores = df_image['confidence'].tolist()\n",
        "            labels = df_image['class'].map(class_map).tolist()\n",
        "\n",
        "            # Filter valid boxes\n",
        "            valid_boxes, valid_scores, valid_labels = [], [], []\n",
        "            for i, box in enumerate(boxes):\n",
        "                if box[2] > box[0] and box[3] > box[1]:\n",
        "                    valid_boxes.append(box)\n",
        "                    valid_scores.append(scores[i])\n",
        "                    valid_labels.append(labels[i])\n",
        "\n",
        "            norm_boxes = [[x[0]/w, x[1]/h, x[2]/w, x[3]/h] for x in valid_boxes]\n",
        "            boxes_list.append(norm_boxes)\n",
        "            scores_list.append(valid_scores)\n",
        "            labels_list.append(valid_labels)\n",
        "\n",
        "        if len(boxes_list) > 0:\n",
        "            boxes, scores, labels = weighted_boxes_fusion(\n",
        "                boxes_list, scores_list, labels_list,\n",
        "                weights=[1] * len(boxes_list),\n",
        "                iou_thr=iou_thr, skip_box_thr=skip_box_thr\n",
        "            )\n",
        "            boxes = [[x[0]*w, x[1]*h, x[2]*w, x[3]*h] for x in boxes]\n",
        "        else:\n",
        "            boxes, scores, labels = [], [], []\n",
        "\n",
        "        if not boxes:\n",
        "            result = pd.DataFrame([{\n",
        "                'Image_ID': image_id, 'class': 'Corn_Healthy', 'confidence': 0.5,\n",
        "                'ymin': 0, 'xmin': 0, 'ymax': 0, 'xmax': 0\n",
        "            }])\n",
        "        else:\n",
        "            result = pd.DataFrame({\n",
        "                'Image_ID': image_id,\n",
        "                'class': [label_map[l] for l in labels],\n",
        "                'confidence': scores,\n",
        "                'ymin': [b[1] for b in boxes],\n",
        "                'xmin': [b[0] for b in boxes],\n",
        "                'ymax': [b[3] for b in boxes],\n",
        "                'xmax': [b[2] for b in boxes],\n",
        "            })\n",
        "\n",
        "        fused_results.append(result)\n",
        "\n",
        "    return pd.concat(fused_results)\n",
        "\n",
        "def generate_submission_with_wbf_multimodel(\n",
        "    test_df,\n",
        "    image_sizes,\n",
        "    model_paths,  # list of models\n",
        "    base_dir,\n",
        "    ensemble_name\n",
        "):\n",
        "    prediction_dfs = []\n",
        "\n",
        "    for idx, model_path in enumerate(model_paths):\n",
        "        intermediate_pred_csv_dir = os.path.join(\n",
        "            \"/kaggle/working/\",\n",
        "            f\"intermediate-predictions/int_preds__fold_{idx}_model_nimgs_{len(image_sizes)}\"\n",
        "        )\n",
        "\n",
        "        # Run inference\n",
        "        print(f\"Running inference with model: {model_path}\")\n",
        "        all_predictions = run_yolo_inference_on_test_set(\n",
        "            test_df=test_df,\n",
        "            image_sizes=image_sizes,\n",
        "            model_path=model_path,\n",
        "            min_conf=0.001\n",
        "        )\n",
        "\n",
        "        # Save raw predictions\n",
        "        save_predictions_to_csv(\n",
        "            predictions=all_predictions,\n",
        "            idx=idx,\n",
        "            output_dir=intermediate_pred_csv_dir\n",
        "        )\n",
        "\n",
        "        # Load predictions for each image size\n",
        "        for imgsz in image_sizes:\n",
        "            csv_path = os.path.join(intermediate_pred_csv_dir, f'preds_{idx}_{imgsz}.csv')\n",
        "            if os.path.exists(csv_path):\n",
        "                df = pd.read_csv(csv_path)\n",
        "                prediction_dfs.append(df)\n",
        "\n",
        "    # WBF\n",
        "    print(\"Merging predictions with WBF\")\n",
        "    df_res_wbf = merge_predictions_with_wbf(\n",
        "        prediction_dfs=prediction_dfs, iou_thr=0.5, skip_box_thr=0.001)\n",
        "\n",
        "    # Save final submission\n",
        "    submission_name = f\"submission_fold_MULTI_MODEL_nimgs_{len(image_sizes)}_{ensemble_name}.csv\"\n",
        "    submission_path = os.path.join('/kaggle/working/', 'submissions', submission_name)\n",
        "    os.makedirs(os.path.dirname(submission_path), exist_ok=True)\n",
        "    df_res_wbf.to_csv(submission_path, index=False)\n",
        "    print(f\"Saved WBF submission to {submission_path}\")\n",
        "\n",
        "    return df_res_wbf\n",
        "\n",
        "\n",
        "def save_predictions_to_csv(predictions, idx, output_dir='test_preds'):\n",
        "    \"\"\"\n",
        "    Saves predictions from all image sizes into separate CSV files.\n",
        "\n",
        "    Args:\n",
        "        predictions (dict): Dictionary of predictions by image size.\n",
        "        output_dir (str): Directory to save CSV files.\n",
        "        fold (int): Fold number for file naming.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for size, preds in predictions.items():\n",
        "        df = pd.DataFrame(preds)\n",
        "        df.to_csv(f'{output_dir}/preds_{idx}_{size}.csv', index=False)\n",
        "        print(f\"Saved predictions for size {size}: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcKDQzGXYzwm"
      },
      "source": [
        "(14402, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:16.602408Z",
          "iopub.status.busy": "2025-04-22T12:20:16.601927Z",
          "iopub.status.idle": "2025-04-22T12:20:16.675454Z",
          "shell.execute_reply": "2025-04-22T12:20:16.674629Z",
          "shell.execute_reply.started": "2025-04-22T12:20:16.602369Z"
        },
        "id": "Vh-NyFoeYzwm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "test = pd.read_csv(Config.path + \"Test.csv\")\n",
        "train =pd.read_csv(Config.path + 'Train.csv')\n",
        "# Construct image paths\n",
        "test['image_path'] = Config.image_path + test['Image_ID']\n",
        "\n",
        "# strip any spacing from the class item and make sure it is a string\n",
        "train['class'] = train['class'].str.strip()\n",
        "class_map = {cls: i for i, cls in enumerate(sorted(train['class'].unique().tolist()))}\n",
        "label_map = {v:k for k,v in class_map.items()}\n",
        "\n",
        "# Validate uniqueness of image IDs\n",
        "assert len(test) == test['Image_ID'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-22T12:20:16.677085Z",
          "iopub.status.busy": "2025-04-22T12:20:16.676502Z",
          "iopub.status.idle": "2025-04-22T12:20:16.683842Z",
          "shell.execute_reply": "2025-04-22T12:20:16.682836Z",
          "shell.execute_reply.started": "2025-04-22T12:20:16.677046Z"
        },
        "id": "jFQ56s9iYzwn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test['image_path'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "execution_failed": "2025-04-22T12:22:26.651Z",
          "iopub.execute_input": "2025-04-22T12:20:16.685489Z",
          "iopub.status.busy": "2025-04-22T12:20:16.685045Z"
        },
        "id": "jRFSOxw5Yzwn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#3,5,7,8\n",
        "image_sizes = [640, 800,960, 1120, 1280, 1440]\n",
        "models = ['/kaggle/input/yolo11s-6-7-8/Inference_Weights/runs/detect/train_fold_6_model_yolo11s_imgs_800/weights/best.pt',\n",
        "          '/kaggle/input/yolo11s-6-7-8/Inference_Weights/runs/detect/train_fold_7_model_yolo11s_imgs_800/weights/best.pt',\n",
        "            '/kaggle/input/yolo11s-6-7-8/Inference_Weights/runs/detect/train_fold_8_model_yolo11s_imgs_800/weights/best.pt',\n",
        "         ]\n",
        "base_dir = \"/kaggle/input/yolo11s_6_7_8\"\n",
        "\n",
        "final_submission = generate_submission_with_wbf_multimodel(\n",
        "    test_df=test,\n",
        "    image_sizes=image_sizes,\n",
        "    model_paths=models,\n",
        "    base_dir=base_dir,\n",
        "    ensemble_name = \"yolo11s_800_6_7_8(127)_min_conf_001_10folds_10bs_valid_halfed\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 11762985,
          "datasetId": 7091683,
          "sourceId": 11336886,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 11220359,
          "datasetId": 6743253,
          "sourceId": 10856302,
          "sourceType": "datasetVersion"
        },
        {
          "databundleVersionId": 12283432,
          "datasetId": 7122379,
          "sourceId": 11795130,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
